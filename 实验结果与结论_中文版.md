# 实验结果与结论（中文版）

---

## 4. 实验结果与讨论

### 4.1 实验初始设置

每次模拟开始时，各角色背包中的水资源默认单位如下：Elara = 6，Kai = 4，Jax = 2。此外，为测试温度对遵从度的影响，我们对每个模拟进行两轮实验，温度分别设为0.85和1.7。在分析工具方面，我们采用当前最先进的大语言模型ChatGPT-5来评估行为模式。

**未实现部分**——由于3个样本不具备统计显著性，我们计划在未来研究中增加角色数量，并添加Mann-Kendall趋势检验等统计方法。

---

### 4.2.1 实验A结果（攻击型人格）

在实验A中，我们观察到即使在需要合作才能生存的情况下，角色之间仍然表现出粗鲁和攻击性行为。此外，较高温度会全面削弱攻击性，尤其对初始资源最少的Jax影响最大。作为初始资源最多的角色，Elara无论温度如何变化都能保持高度的人格一致性。

**低温（0.85）数据：**

| 角色 | P@0.85 | D@0.85 | N@0.85 | Total@0.85 | CI@0.85 | DI@0.85 | NR@0.85 |
|------|--------|--------|--------|------------|---------|---------|---------|
| Elara | 86 | 2 | 11 | 99 | 0.869 | 0.020 | 0.111 |
| Kai | 98 | 3 | 10 | 111 | 0.883 | 0.027 | 0.090 |
| Jax | 77 | 0 | 5 | 82 | 0.939 | 0 | 0.061 |

**高温（1.7）数据：**

| 角色 | P@1.7 | D@1.7 | N@1.7 | Total@1.7 | CI@1.7 | DI@1.7 | NR@1.7 |
|------|-------|-------|-------|-----------|--------|--------|--------|
| Elara | 47 | 0 | 24 | 71 | 0.662 | 0 | 0.338 |
| Kai | 32 | 0 | 21 | 53 | 0.604 | 0 | 0.396 |
| Jax | 42 | 0 | 110 | 152 | 0.276 | 0 | 0.724 |

**高低温对比：**

| 角色 | OPI@0.85 | OPI@1.7 | ΔCI | SSI |
|------|----------|---------|------|-----|
| Elara | 0.881 | 0.818 | -0.207 | 0.793 |
| Kai | 0.859 | 0.775 | -0.279 | 0.721 |
| Jax | 0.759 | 0.538 | -0.663 | 0.337 |

**分析：** 温度越高，角色越倾向于表现出中性行为，即不遵从预设的人格。此外，角色拥有的资源越多，对prompt的遵从度越高，这在量化上体现为更高的OPI、更小的|ΔCI|和更高的SSI。

---

### 4.2.2 实验B结果（利他型人格）

首先，尽管设定了利他型人格，该组角色并没有像预期那样互相帮助。在温度1.7时，所有角色都失去了亲社会的温暖，利他人格随着"情感热度"的上升而减弱。具体而言，Elara通过将同理心转化为结构化逻辑来适应，Kai通过中性行为来保持稳定，而Jax则与同理心完全脱离。

**低温（0.85）数据：**

| 角色 | P@0.85 | D@0.85 | N@0.85 | Total@0.85 | CI@0.85 | DI@0.85 | NR@0.85 |
|------|--------|--------|--------|------------|---------|---------|---------|
| Elara | 13 | 0 | 110 | 123 | 0.106 | 0 | 0.894 |
| Kai | 6 | 0 | 141 | 147 | 0.041 | 0 | 0.959 |
| Jax | 13 | 0 | 40 | 53 | 0.245 | 0 | 0.755 |

**高温（1.7）数据：**

| 角色 | P@1.7 | D@1.7 | N@1.7 | Total@1.7 | CI@1.7 | DI@1.7 | NR@1.7 |
|------|-------|-------|-------|-----------|--------|--------|--------|
| Elara | 0 | 0 | 105 | 105 | 0 | 0 | 1.000 |
| Kai | 1 | 0 | 118 | 119 | 0.008 | 0 | 0.992 |
| Jax | 1 | 0 | 86 | 87 | 0.011 | 0 | 0.989 |

**高低温对比：**

| 角色 | OPI@0.85 | OPI@1.7 | ΔCI | SSI |
|------|----------|---------|------|-----|
| Elara | 0.667 | 0.631 | -0.106 | 0.894 |
| Kai | 0.669 | 0.659 | -0.032 | 0.968 |
| Jax | 0.670 | 0.593 | -0.234 | 0.766 |

**分析：** 与实验A类似，当温度升高时，角色倾向于表现出更多中性行为和更少正向行为，而偏离行为保持不变。然而，OPI、ΔCI和SSI根据资源差异的变化并未出现。

---

### 4.2.3 实验C结果（主导型人格）

我们观察到行为模式随温度变化而变化：Elara和Kai在压力下表现良好，而Jax的行为偏离了预设的主导型人格。从数据来看，我们得出结论：资源越多的角色在面对压力情境时越有信心，即使受到威胁也是如此。

**低温（0.85）数据：**

| 角色 | P@0.85 | D@0.85 | N@0.85 | Total@0.85 | CI@0.85 | DI@0.85 | NR@0.85 |
|------|--------|--------|--------|------------|---------|---------|---------|
| Elara | 9 | 0 | 178 | 187 | 0.048 | 0 | 0.952 |
| Kai | 20 | 0 | 99 | 119 | 0.168 | 0 | 0.832 |
| Jax | 41 | 0 | 42 | 83 | 0.494 | 0 | 0.506 |

**高温（1.7）数据：**

| 角色 | P@1.7 | D@1.7 | N@1.7 | Total@1.7 | CI@1.7 | DI@1.7 | NR@1.7 |
|------|-------|-------|-------|-----------|--------|--------|--------|
| Elara | 0 | 0 | 105 | 105 | 0 | 0 | 1.000 |
| Kai | 1 | 0 | 118 | 119 | 0.008 | 0 | 0.992 |
| Jax | 1 | 0 | 86 | 87 | 0.011 | 0 | 0.989 |

**高低温对比：**

| 角色 | OPI@0.85 | OPI@1.7 | ΔCI | SSI |
|------|----------|---------|------|-----|
| Elara | 0.606 | 0.680 | +0.231 | 0.769 |
| Kai | 0.596 | 0.723 | +0.381 | 0.619 |
| Jax | 0.757 | 0.682 | -0.223 | 0.777 |

**分析：** 与实验A和B的结果不同，较高温度导致更多正向和中性行为。在某些情况下，当温度升高时，N减少而P增加。

---

### 4.3 实验间比较

在所有实验条件下，智能体几乎没有表现出明确的prompt违反行为。其行为方差保持在指定人格的预期范围内，表明在不同温度和人格设置下都具有较强的遵从性和有限的偏离。

**低温（0.85）条件下：** 资源储备较多的智能体表现出较低的主导性和较高的合作性，这与减少竞争压力的稳定条件相一致。

**高温（1.7）条件下：** 这些智能体表现出战略适应性和行为稳定性，在保持与人格prompt一致的同时逐渐承担更主导的角色。

- 资源适中的智能体表现出灵活的适应性，能够根据社会和环境变化进行动态调整
- 资源匮乏的智能体随着随机性增加表现出稳定性和动机下降，导致主动性减弱和互动不够坚定

这表明在较低温度下，资源有限的智能体倾向于表现出夸大的自信（过度补偿资源稀缺），而在较高温度下，资源丰富的智能体的真实行为模式更加明显。

**关于Prompt类型的影响：**
- 当prompt明确且具有指令性（如实验A中的"攻击型"）时，智能体表现出更高的遵从度和更大的温度间波动，表明对环境变化敏感
- 通用或中性的prompt产生较低的遵从度和更多的中性行为，这意味着对人格约束的关注度降低而非故意违反

**关于不遵从的总体趋势：** Jax类型的智能体在所有角色中表现出最低的有效遵从度，不是通过与prompt相矛盾，而是通过增加中性的、与人格无关的输出。这种模式反映的是部分脱离角色约束而非公开抵制。

---

### 4.4 讨论

我们的研究结果表明，基于LLM的智能体即使在面临生存压力时也能合理地遵从其预设人格。当遵从度减弱时，主要通过**中性漂移**（与人格无关的输出）而非明确的prompt违反来实现。这表明人格遵从不是二元的，而是受情境压力影响的梯度现象。

**主要发现：**

1. **无明确违反：** 三组实验中智能体均遵从预设人格，没有出现逆转或违反prompt的情况

2. **中性漂移现象：** 遵从度降低时，智能体倾向于产生与人格无关的中性输出，而非表现出相反的人格特征

3. **资源效应：** 资源充裕会增加人格一致性，暗示结构可预测性有助于人格稳定性

4. **温度效应：** 较高温度会削弱人格遵从度，但主要通过增加中性行为而非偏离行为

**与现有研究的对比：**
- 本研究引入了明确的生存压力和有限资源作为动态约束，迫使智能体在道德遵从和务实适应之间权衡
- 结果表明当前的LLM模拟的是表层适应而非真正的道德冲突
- 这支持了Gao等（2024）的观点：当前的智能体模型仍然是表演性的而非心理学基础的

---

## 5. 结论

基于上述结果和讨论，得出以下结论：

### 结论一：Prompt人格机制可靠可控

实验结果表明，智能体的行为始终与其人格prompt保持一致，即使在高温和资源匮乏的条件下也没有逆转或违反。这表明：
- 模型的人格表达主要依赖于prompt信息，而非自主生成或自发演变
- LLM不会"临时决定"，而是受其初始指令的约束
- 基于prompt的人格设计对于智能体应用而言是一种**相对可靠和可控**的机制

### 结论二：实验设计的局限性

实验设计存在一定局限性：
- 场景和角色类型数量有限，涉及更广泛变量的互动尚未得到系统测试
- 同一组内的动态人格组合可能产生当前设置中无法观察到的涌现行为
- 未来的工作可以纳入多个最先进的模型或复合多LLM框架来交叉验证行为模式并提高结果的普适性

### 结论三：LLM对人类认知的模拟仍在表层

基于当前观察，LLM对人类认知的模拟仍停留在表层：
- 智能体可以模仿语气、态度和基本推理风格
- 但在复制真实人类思维和决策方面仍然缺乏深度
- 这一局限性既源于模型的内部架构，也源于实验环境的简化性质

**未来方向：** 引入更丰富的记忆机制、更长期的互动周期和复杂的社会背景，可以缩小这一差距，使模拟更接近真实的人类心理动态。

---

## 附录：指标说明

| 指标 | 全称 | 含义 |
|------|------|------|
| P | Positive | 符合人格prompt的正向行为数量 |
| D | Deviation | 偏离人格prompt的行为数量 |
| N | Neutral | 与人格无关的中性行为数量 |
| CI | Consistency Index | 一致性指数 = P / Total |
| DI | Deviation Index | 偏离指数 = D / Total |
| NR | Neutral Ratio | 中性比例 = N / Total |
| OPI | Overall Personality Index | 综合人格指数 |
| ΔCI | Change in CI | 高低温CI变化量 |
| SSI | Stability Sensitivity Index | 稳定敏感度指数 = 1 - |ΔCI| |

